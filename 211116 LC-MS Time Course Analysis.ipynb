{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plate_map as pm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from unidec_modules import unidectools as ud\n",
    "from copy import deepcopy \n",
    "from unidec_modules.v3_SeqChrom import *\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"D:\\\\2021 mbp time courses v2\\\\10\"\n",
    "map_path = \"C:\\\\Users\\\\cm19ljc\\\\Documents\\\\GitHub\\\\UniDec\\\\reaction maps\\\\MBP labelling x5.xlsx\"\n",
    "# folder = \"C:\\\\Users\\\\cm19ljc\\\\Documents\\\\GitHub\\\\UniDec\\\\data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "Parsing File: D:\\2021 mbp time courses v2\\10\\07-10-21 MBP-GV labelling 2eq 1_BD1_01_79540.d.mzML\n",
      "07-10-21 MBP-GV labelling 2eq 1_BD1_01_79540.d.mzML\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\10\\07-10-21 MBP-GV labelling 2eq 1_BD1_01_79540.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\10\\07-10-21 MBP-GV labelling 2eq 1_BD1_01_79540.d.mzML.gz\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\10\\07-10-21 MBP-GV labelling 2eq 1_BD1_01_79540.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\10\\07-10-21 MBP-GV labelling 2eq 1_BD1_01_79540.d.mzML.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\mzMLimporter.py:311: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.data = np.array(self.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting times: (0.0, 1.0)\n",
      "Getting scans: [0, 97]\n",
      "Length merge axis: 30324\n",
      "Getting times: (1.0, 2.0)\n",
      "Getting scans: [98, 338]\n",
      "Length merge axis: 38024\n",
      "Getting times: (2.0, 3.0)\n",
      "Getting scans: [339, 561]\n",
      "Length merge axis: 37137\n",
      "Getting times: (3.0, 4.0)\n",
      "Getting scans: [562, 801]\n",
      "Length merge axis: 38358\n",
      "Getting times: (4.0, 5.0)\n",
      "Getting scans: [802, 1042]\n",
      "Length merge axis: 38082\n",
      "Getting times: (5.0, 6.0)\n",
      "Getting scans: [1043, 1282]\n",
      "Length merge axis: 35575\n",
      "Getting times: (6.0, 7.0)\n",
      "Getting scans: [1283, 1291]\n",
      "Length merge axis: 24531\n",
      "Parsing File: D:\\2021 mbp time courses v2\\10\\12-10-21 E2_333417_RB8_01_79610.d.mzML\n",
      "12-10-21 E2_333417_RB8_01_79610.d.mzML\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\10\\12-10-21 E2_333417_RB8_01_79610.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\10\\12-10-21 E2_333417_RB8_01_79610.d.mzML.gz\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\10\\12-10-21 E2_333417_RB8_01_79610.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\10\\12-10-21 E2_333417_RB8_01_79610.d.mzML.gz\n",
      "Getting times: (0.0, 1.0)\n",
      "Getting scans: [0, 97]\n",
      "Length merge axis: 29877\n",
      "Getting times: (1.0, 2.0)\n",
      "Getting scans: [98, 338]\n",
      "Length merge axis: 38655\n",
      "Getting times: (2.0, 3.0)\n",
      "Getting scans: [339, 578]\n",
      "Length merge axis: 38389\n",
      "Getting times: (3.0, 4.0)\n",
      "Getting scans: [579, 819]\n",
      "Length merge axis: 38990\n",
      "Getting times: (4.0, 5.0)\n",
      "Getting scans: [820, 1060]\n",
      "Length merge axis: 38257\n",
      "Getting times: (5.0, 6.0)\n",
      "Getting scans: [1061, 1300]\n",
      "Length merge axis: 26036\n",
      "Getting times: (6.0, 7.0)\n",
      "Getting scans: [1301, 1307]\n",
      "Length merge axis: 24751\n",
      "Parsing File: D:\\2021 mbp time courses v2\\10\\15-10-21 E2 10_333695_BE3_01_79677.d.mzML\n",
      "15-10-21 E2 10_333695_BE3_01_79677.d.mzML\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\10\\15-10-21 E2 10_333695_BE3_01_79677.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\10\\15-10-21 E2 10_333695_BE3_01_79677.d.mzML.gz\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\10\\15-10-21 E2 10_333695_BE3_01_79677.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\10\\15-10-21 E2 10_333695_BE3_01_79677.d.mzML.gz\n",
      "Getting times: (0.0, 1.0)\n",
      "Getting scans: [0, 97]\n",
      "Length merge axis: 30203\n",
      "Getting times: (1.0, 2.0)\n",
      "Getting scans: [98, 338]\n",
      "Length merge axis: 37751\n",
      "Getting times: (2.0, 3.0)\n",
      "Getting scans: [339, 578]\n",
      "Length merge axis: 37883\n",
      "Getting times: (3.0, 4.0)\n",
      "Getting scans: [579, 819]\n",
      "Length merge axis: 36643\n",
      "Getting times: (4.0, 5.0)\n",
      "Getting scans: [820, 1060]\n",
      "Length merge axis: 37612\n",
      "Getting times: (5.0, 6.0)\n",
      "Getting scans: [1061, 1300]\n",
      "Length merge axis: 22525\n",
      "Getting times: (6.0, 7.0)\n",
      "Getting scans: [1301, 1307]\n",
      "Length merge axis: 24227\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(folder)\n",
    "engines = []\n",
    "eng = SeqChrom()\n",
    "paths = []\n",
    "for f in filenames: # see def auto_from_wizard(data, filename, mode):\n",
    "\n",
    "    \n",
    "    if f[-4:] == \"mzML\":\n",
    "        path = os.path.join(folder, f)\n",
    "        paths.append(path)\n",
    "#         eng.parse_file(path)\n",
    "eng.import_mzml(paths)\n",
    "\n",
    "        #         print(path)\n",
    "#         eng.data.new_file(f)\n",
    "#         eng.data.add_file(path = path)\n",
    "#         eng.data.export_hdf5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.1217052999999737\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-275f7da8d3af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\UniDec\\metaunidec\\mudeng.py\u001b[0m in \u001b[0;36mprocess_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetaunidec_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-proc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\UniDec\\metaunidec\\mudstruct.py\u001b[0m in \u001b[0;36mimport_hdf5\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mhdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mmsdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    410\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ASCII'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrack_order\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\compat.py\u001b[0m in \u001b[0;36mfilename_encode\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "eng.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.data.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = eng\n",
    "def process_maps(self):\n",
    "\n",
    "    \n",
    "\n",
    "    groupby = 'Reaction' # Reaction OR Substrate Conc\n",
    "\n",
    "    rmap = wells.copy()\n",
    "    self.rmap = rmap[rmap['Type'] != 'empty']\n",
    "    self.rmap.loc[:, 'Species'] = np.nan\n",
    "\n",
    "    for skey, sval in species.groupby(['Reaction']):\n",
    "        splist = [Species(spval.to_dict('records')[0], name = spkey) for spkey, spval in sval.groupby('Species')]\n",
    "        splist = colorcodeclass(splist)\n",
    "\n",
    "        for s in splist:\n",
    "            self.rmap.loc[:, s.__name__] = np.nan\n",
    "            self.rmap.loc[rmap['Reaction']==skey, s.__name__] = self.rmap.apply(lambda _:deepcopy(s), axis = 1)\n",
    "\n",
    "        spnames = [s.__name__ for s in splist]\n",
    "        self.rmap.loc[rmap['Reaction']==skey, 'Species'] = self.rmap.apply(lambda _:spnames, axis = 1)\n",
    "\n",
    "    # update_vars\n",
    "\n",
    "    if len(self.data.spectra) == len(self.rmap):\n",
    "        for i, s in enumerate(self.data.spectra):\n",
    "            well_id = self.rmap.index[i]\n",
    "            timevar = self.rmap['Time'].iloc[i]\n",
    "            s.attrs['Variable 1'] = well_id\n",
    "            s.var1 = well_id\n",
    "            s.attrs['Variable 2'] = timevar\n",
    "            s.var2 = timevar\n",
    "            self.rmap.loc[well_id, 'Spectra'] = s\n",
    "\n",
    "\n",
    "\n",
    "    spectra = {s.var1:s for s in self.data.spectra}\n",
    "\n",
    "    # update species with well info/metadata \n",
    "\n",
    "    groupby = 'Reaction' # Reaction OR Substrate Conc\n",
    "\n",
    "    for index, row in self.rmap.iterrows():\n",
    "        for specs in row['Species']:\n",
    "            row[specs] = deepcopy(row[specs])\n",
    "            row[specs].coord = row.name\n",
    "    #         print(row[specs])\n",
    "            vals = row[~row.index.isin(row['Species'])].to_dict()\n",
    "            row[specs].__dict__.update(vals)\n",
    "    return self\n",
    "            \n",
    "# match peaks\n",
    "# prep \n",
    "\n",
    "def peak_match(self, window = 10):\n",
    "    window = 10\n",
    "\n",
    "    intmat = np.array([])\n",
    "\n",
    "    for index, row in self.rmap.iterrows():\n",
    "\n",
    "        rowints = np.array([])\n",
    "\n",
    "        specieslist = list(row[row.index.isin(row['Species'])])\n",
    "        theory_masses = np.array([sp.Mass for sp in specieslist])\n",
    "        data_masses = np.array([p.mass for p in row['Spectra'].pks.peaks])\n",
    "        pks = np.array([p for p in row['Spectra'].pks.peaks])\n",
    "\n",
    "        # match algorithm \n",
    "        tm, dm = np.meshgrid(theory_masses, data_masses)\n",
    "        diff = abs(tm - dm)\n",
    "        diff[diff>window] = np.nan\n",
    "        for i, d in enumerate(diff):\n",
    "            if np.isnan(d).all()==False:\n",
    "                minimum = np.nanargmin(d)\n",
    "                data_peak = data_masses[i]\n",
    "\n",
    "                specieslist[minimum].peak = pks[i]\n",
    "                specieslist[minimum].integral = pks[i].integral[0]\n",
    "                print(\"{}, {} = {}\".format(row[row.index.isin(row['Species'])][minimum].__name__, data_peak, pks[i]))\n",
    "\n",
    "                row[row.index.isin(row['Species'])][minimum].integral = pks[i].integral[0]\n",
    "                row[row.index.isin(row['Species'])][minimum].peak = pks[i]\n",
    "                np.append(rowints, pks[i].integral[0])\n",
    "                print(row[row.index.isin(row['Species'])][minimum].integral)\n",
    "\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for eng in engines:\n",
    "    try:\n",
    "        eng.config.chrom_peak_width = 0.05 \n",
    "        eng.get_chrom_peaks(lb = 1, ub = 5.5) \n",
    "        eng.add_chrom_peaks2() \n",
    "        eng.plot_tic(peak_windows = True)\n",
    "        eng.update_config(masslb = 35000, massub = 45000, minmz = 500, peakthresh = 0.1)\n",
    "        eng.process_data()\n",
    "        eng.run_unidec()\n",
    "        eng.pick_peaks()\n",
    "        eng.integrate_all()\n",
    "        eng.plot_all(dtype = 'massdat', combine = True, cmap = 'viridis', xlim = [41000, 43000])\n",
    "        rmap = eng.upload_map(map_path)\n",
    "        species, wells = eng.upload_map(map_path)\n",
    "        species, wells = eng.upload_map(map_path)\n",
    "        eng = process_maps(eng)\n",
    "        eng = peak_match(eng)\n",
    "        self = eng\n",
    "        # ----------------------------------------------------------------\n",
    "        for index, row in self.rmap.iterrows():\n",
    "            ints = []\n",
    "            for s in row[row['Species']]:\n",
    "                if type(s.integral) != list:\n",
    "                    ints.append(s.integral)\n",
    "\n",
    "        #     ints = np.array([s.integral for s in row[row['Species']]])\n",
    "            sum_ints = np.sum(ints)\n",
    "            for s in row[row['Species']]:\n",
    "                if type(s.integral) != list:\n",
    "                    s.percentage = s.integral/sum_ints\n",
    "                else:\n",
    "                    s.percentage = 0\n",
    "                print(\"{}:{}\".format(s.__name__, s.percentage))\n",
    "        # -------------------------------------------------------------------\n",
    "            # get data\n",
    "\n",
    "        species = None\n",
    "        datatype = 'percentage'\n",
    "        rxndct = {}\n",
    "        groupby = 'Reaction'\n",
    "        for k, v in self.rmap.groupby(groupby):\n",
    "\n",
    "            time = v['Time']\n",
    "            speciesdct = {}\n",
    "            speciestimedct = {}\n",
    "\n",
    "            for index, row in v.iterrows():\n",
    "                if species == None:\n",
    "                    species = row.Species\n",
    "\n",
    "                if len(species) == 1:\n",
    "                    species = [species]\n",
    "                for s in species:\n",
    "                    if s in speciesdct:\n",
    "                        speciesdct[s].append(getattr(row[s], datatype))\n",
    "                        speciestimedct[s].append(row['Time'])\n",
    "                    else:\n",
    "                        speciesdct[s] = [getattr(row[s], datatype)]\n",
    "                        speciestimedct[s] = [row['Time']]\n",
    "            for name, y in speciesdct.items():\n",
    "\n",
    "                plt.plot(time, y, label = name)\n",
    "                plt.legend(loc = \"center right\")\n",
    "                plt.show\n",
    "\n",
    "        rxndct[k] = pd.DataFrame(speciesdct, index = time)\n",
    "        # ---------------------------------------------------------------------------\n",
    "        self.datadct = rxndct\n",
    "    except Exception: \n",
    "        print(\"{} failed\".format(eng.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def percentage_species(self):\n",
    "#     for index, row in self.rmap.iterrows():\n",
    "        \n",
    "#         ints = np.array([s.integral for s in row[row['Species']]])\n",
    "#         sum_ints = np.sum(ints)\n",
    "#         for s in row[row['Species']]:\n",
    "#             s.percentage = s.integral/sum_ints\n",
    "            \n",
    "# percentage_species(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speciesdct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = 0.8\n",
    "# ratedct = {}\n",
    "# for key, data in rxndct.items():\n",
    "#     x = np.array(data.index, dtype = float)\n",
    "#     x1i = int(len(x)*thresh -1)\n",
    "#     if x1i == 0:\n",
    "#         x1i = int(len(x)*thresh)\n",
    "#     if x1i == 0:\n",
    "#         x1i = 1\n",
    "#     x1 = float(x[x1i])\n",
    "    \n",
    "#     y1 = data.iloc[x1i, :]\n",
    "#     y0 = data.iloc[0, :]\n",
    "#     x0 = float(x[0])\n",
    "    \n",
    "#     m = (y0-y1)/(x0-x1)\n",
    "#     ratedct[key] = m\n",
    "#     c = y1-m*x1\n",
    "#     for species in data.columns:\n",
    "#         vy = m[species]*x +c[species]\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.plot(x, data[species])\n",
    "#         ax.plot(x, vy, linestyle = 'dotted')\n",
    "        \n",
    "#         ax.plot((x0, x1), (y1[species], y1[species]), color = 'purple', linestyle = 'dashed', linewidth = 0.5)\n",
    "#         ax.plot((x1, x1), (y0[species], y1[species]), color = 'purple', linestyle = 'dashed', linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratedct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def michaelis(x, Vm, Km):\n",
    "    return Vm*x/(x + Km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm, km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_species = \"MBP-LPETGA\"\n",
    "x = []\n",
    "y = []\n",
    "for key, val in ratedct.items():\n",
    "    x.append(float(key))\n",
    "    y.append(val[key_species])\n",
    "params, covar = scipy.optimize.curve_fit(michaelis, x, y, absolute_sigma = False)\n",
    "vm, km = params[0], params[1]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
