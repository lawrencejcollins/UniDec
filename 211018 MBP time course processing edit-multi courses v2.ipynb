{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plate_map as pm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from unidec_modules import unidectools as ud\n",
    "from copy import deepcopy \n",
    "from unidec_modules.v3_SeqChrom import *\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"D:\\\\2021 mbp time courses v2\\\\25\"\n",
    "map_path = \"C:\\\\Users\\\\cm19ljc\\\\Documents\\\\GitHub\\\\UniDec\\\\reaction maps\\\\MBP labelling x5 25pc.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "Opening HDF5 File: D:\\2021 mbp time courses v2\\25\\12-10-21 E1_333416_RB7_01_79609.d.hdf5\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\25\\12-10-21 E1_333416_RB7_01_79609.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\25\\12-10-21 E1_333416_RB7_01_79609.d.mzML.gz\n",
      "Error getting TIC in mzML; trying to make it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\mzMLimporter.py:311: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.data = np.array(self.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Data. Constructing TIC\n",
      "Done\n",
      "loaded D:\\2021 mbp time courses v2\\25\\12-10-21 E1_333416_RB7_01_79609.d.mzML\n",
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "Opening HDF5 File: D:\\2021 mbp time courses v2\\25\\15-10-21 E1 25_333694_BE2_01_79676.d.hdf5\n",
      "Reading mzML: D:\\2021 mbp time courses v2\\25\\15-10-21 E1 25_333694_BE2_01_79676.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n",
      "Converted to gzip file to improve speed: D:\\2021 mbp time courses v2\\25\\15-10-21 E1 25_333694_BE2_01_79676.d.mzML.gz\n",
      "Error getting TIC in mzML; trying to make it...\n",
      "Imported Data. Constructing TIC\n",
      "Done\n",
      "loaded D:\\2021 mbp time courses v2\\25\\15-10-21 E1 25_333694_BE2_01_79676.d.mzML\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(folder)\n",
    "engines = []\n",
    "for dname, dirs, files in os.walk(folder):\n",
    "    \n",
    "    for fname in files:\n",
    "        \n",
    "        if fname[-4:] == \"mzML\":\n",
    "            eng = SeqChrom()\n",
    "\n",
    "            spectra_path = os.path.join(dname, fname)\n",
    "            eng.load_mzml(spectra_path)\n",
    "            print(\"loaded {}\".format(spectra_path))\n",
    "            engines.append(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_maps(self, groupby = 'Reaction'):\n",
    "\n",
    "    \n",
    "\n",
    "    # Reaction OR Substrate Conc\n",
    "\n",
    "    self.pmap2 = self.pmap[self.pmap['Type'] != 'empty']\n",
    "    self.pmap2.loc[:, 'Species'] = np.nan\n",
    "\n",
    "    for skey, sval in self.speciesmap.groupby(['Reaction']):\n",
    "        splist = [Species(spval.to_dict('records')[0], name = spkey) for spkey, spval in sval.groupby('Species')]\n",
    "        splist = colorcodeclass(splist)\n",
    "\n",
    "        for s in splist:\n",
    "            self.pmap2.loc[:, s.__name__] = np.nan\n",
    "            self.pmap2.loc[self.pmap2['Reaction']==skey, s.__name__] = self.pmap2.apply(lambda _:deepcopy(s), axis = 1)\n",
    "\n",
    "        spnames = [s.__name__ for s in splist]\n",
    "        self.pmap2.loc[self.pmap2['Reaction']==skey, 'Species'] = self.pmap2.apply(lambda _:spnames, axis = 1)\n",
    "\n",
    "    # update_vars\n",
    "\n",
    "    if len(self.data.spectra) == len(self.pmap2):\n",
    "        for i, s in enumerate(self.data.spectra):\n",
    "            well_id = self.pmap2.index[i]\n",
    "            timevar = self.pmap2['Time'].iloc[i]\n",
    "            s.attrs['Variable 1'] = well_id\n",
    "            s.var1 = well_id\n",
    "            s.attrs['Variable 2'] = timevar\n",
    "            s.var2 = timevar\n",
    "            self.pmap2.loc[well_id, 'Spectra'] = s\n",
    "\n",
    "\n",
    "\n",
    "    spectra = {s.var1:s for s in self.data.spectra}\n",
    "\n",
    "    # update species with well info/metadata \n",
    "\n",
    "    groupby = 'Reaction' # Reaction OR Substrate Conc\n",
    "\n",
    "    for index, row in self.pmap2.iterrows():\n",
    "        for specs in row['Species']:\n",
    "            row[specs] = deepcopy(row[specs])\n",
    "            row[specs].coord = row.name\n",
    "    #         print(row[specs])\n",
    "            vals = row[~row.index.isin(row['Species'])].to_dict()\n",
    "            row[specs].__dict__.update(vals)\n",
    "    return self\n",
    "            \n",
    "\n",
    "def peak_match(self, window = 10):\n",
    "    window = 10\n",
    "\n",
    "    intmat = np.array([])\n",
    "\n",
    "    for index, row in self.pmap2.iterrows():\n",
    "\n",
    "        rowints = np.array([])\n",
    "\n",
    "        specieslist = list(row[row.index.isin(row['Species'])])\n",
    "        theory_masses = np.array([sp.Mass for sp in specieslist])\n",
    "        data_masses = np.array([p.mass for p in row['Spectra'].pks.peaks])\n",
    "        pks = np.array([p for p in row['Spectra'].pks.peaks])\n",
    "\n",
    "        # match algorithm \n",
    "        tm, dm = np.meshgrid(theory_masses, data_masses)\n",
    "        diff = abs(tm - dm)\n",
    "        diff[diff>window] = np.nan\n",
    "        for i, d in enumerate(diff):\n",
    "            if np.isnan(d).all()==False:\n",
    "                minimum = np.nanargmin(d)\n",
    "                data_peak = data_masses[i]\n",
    "\n",
    "                specieslist[minimum].peak = pks[i]\n",
    "                specieslist[minimum].integral = pks[i].integral[0]\n",
    "                print(\"{}, {} = {}\".format(row[row.index.isin(row['Species'])][minimum].__name__, data_peak, pks[i]))\n",
    "\n",
    "                row[row.index.isin(row['Species'])][minimum].integral = pks[i].integral[0]\n",
    "                row[row.index.isin(row['Species'])][minimum].peak = pks[i]\n",
    "                np.append(rowints, pks[i].integral[0])\n",
    "                print(row[row.index.isin(row['Species'])][minimum].integral)\n",
    "\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_peaks(self):\n",
    "    for index, row in self.pmap2.iterrows():\n",
    "        ints = []\n",
    "        for s in row[row['Species']]:\n",
    "            if type(s.integral) != list:\n",
    "                ints.append(s.integral)\n",
    "\n",
    "    #     ints = np.array([s.integral for s in row[row['Species']]])\n",
    "        sum_ints = np.sum(ints)\n",
    "        for s in row[row['Species']]:\n",
    "            if type(s.integral) != list:\n",
    "                s.percentage = s.integral/sum_ints\n",
    "            else:\n",
    "                s.percentage = 0\n",
    "            print(\"{}:{}\".format(s.__name__, s.percentage))\n",
    "            \n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1308 2\n",
      "Noise Level: 0.12485162352255635 Window: 0.05\n",
      "Bad Peak [0.41935    0.59168096] 0.24186700000000005 [0.41935, 0.661217]\n",
      "Bad Peak [0.602567   0.50517104] 0.24603299999999995 [0.41935, 0.665383]\n",
      "1.20155 0.13712999999999997\n",
      "2.15345 0.13295000000000012\n",
      "3.06365 0.1828299999999996\n",
      "3.9904 0.18698000000000015\n",
      "4.93377 0.17037999999999975\n",
      "5.96038 0.06651999999999969\n",
      "Getting scans: [136, 169]\n",
      "Length merge axis: 38450\n",
      "Getting scans: [366, 398]\n",
      "Length merge axis: 37431\n",
      "Getting scans: [586, 630]\n",
      "Length merge axis: 38495\n",
      "Getting scans: [811, 856]\n",
      "Length merge axis: 38432\n",
      "Getting scans: [1036, 1077]\n",
      "Length merge axis: 39522\n",
      "Execution Time: 0.1442418000000032\n",
      "Execution Time: 6.7201357\n",
      "Execution Time: 0.3106991000000008\n",
      "Peak info saved to: D:\\2021 mbp time courses v2\\25\\UniDec_Figures_and_Files\\12-10-21 E1_333416_RB7_01_79609.d_extracts.txt\n",
      "D:\\2021 mbp time courses v2\\25\\12-10-21 E1_333416_RB7_01_79609.d.mzML failed\n",
      "1307 2\n",
      "Noise Level: 0.06088758097740972 Window: 0.05\n",
      "Bad Peak [0.418733   0.65564129] 0.24603399999999997 [0.418733, 0.664767]\n",
      "Bad Peak [0.60195   0.5446013] 0.25434999999999997 [0.418733, 0.673083]\n",
      "1.20092 0.1620499999999998\n",
      "Bad Peak [1.6248     0.06659749] 1.326587 [0.418733, 1.74532]\n",
      "2.13183 0.15377000000000018\n",
      "Bad Peak [2.70123    0.27779883] 0.22856000000000032 [2.61812, 2.84668]\n",
      "3.07527 0.15793999999999997\n",
      "4.0063 0.1496000000000004\n",
      "4.95388 0.16206999999999994\n",
      "5.96395 0.10806000000000004\n",
      "Getting scans: [137, 176]\n",
      "Length merge axis: 38654\n",
      "Getting scans: [361, 398]\n",
      "Length merge axis: 38696\n",
      "Getting scans: [587, 625]\n",
      "Length merge axis: 37526\n",
      "Getting scans: [813, 849]\n",
      "Length merge axis: 37651\n",
      "Getting scans: [1038, 1077]\n",
      "Length merge axis: 37391\n",
      "Execution Time: 0.15977709999999945\n",
      "Execution Time: 6.723728100000002\n",
      "Execution Time: 0.32242920000000197\n",
      "Peak info saved to: D:\\2021 mbp time courses v2\\25\\UniDec_Figures_and_Files\\15-10-21 E1 25_333694_BE2_01_79676.d_extracts.txt\n",
      "D:\\2021 mbp time courses v2\\25\\15-10-21 E1 25_333694_BE2_01_79676.d.mzML failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "df1 = pd.DataFrame()\n",
    "dflist = []\n",
    "for eng in engines:\n",
    "    try:\n",
    "        eng.config.chrom_peak_width = 0.05 \n",
    "        eng.get_chrom_peaks(lb = 1, ub = 5.5) \n",
    "        eng.add_chrom_peaks2() \n",
    "#         eng.plot_tic(peak_windows = True)\n",
    "        eng.update_config(masslb = 35000, massub = 45000, minmz = 500, peakthresh = 0.1)\n",
    "        eng.process_data()\n",
    "        eng.run_unidec()\n",
    "        eng.pick_peaks()\n",
    "        eng.integrate_all()\n",
    "#         eng.plot_all(dtype = 'massdat', combine = True, cmap = 'viridis', xlim = [41000, 43000])\n",
    "        rmap = eng.upload_map(map_path)\n",
    "        species, wells = eng.upload_map(map_path)\n",
    "        eng = process_maps(eng)\n",
    "        eng = peak_match(eng)\n",
    "        eng = normalise_peaks(eng)\n",
    "        self = eng\n",
    "        # get data\n",
    "\n",
    "        species = None\n",
    "        datatype = 'percentage'\n",
    "        rxndct = {}\n",
    "        groupby = 'Reaction'\n",
    "\n",
    "        # def extract_data(self):\n",
    "\n",
    "        rxns_tc = []\n",
    "        for k, v in self.pmap2.groupby(groupby):\n",
    "\n",
    "            time = v['Time']\n",
    "            speciesdct = {}\n",
    "            speciestimedct = {}\n",
    "\n",
    "            for index, row in v.iterrows():\n",
    "                if species == None:\n",
    "                    species = row.Species\n",
    "\n",
    "                if len(species) == 1:\n",
    "                    species = [species]\n",
    "\n",
    "                for s in species:\n",
    "                    if s in speciesdct:\n",
    "                        speciesdct[s].append(getattr(row[s], datatype))\n",
    "                        speciestimedct[s].append(row['Time'])\n",
    "\n",
    "                    else:\n",
    "                        speciesdct[s] = [getattr(row[s], datatype)]\n",
    "                        speciestimedct[s] = [row['Time']]\n",
    "            df = pd.DataFrame(speciesdct, index = time)\n",
    "            rxns_tc.append(df)\n",
    "\n",
    "        if len(rxns_tc) == 1:\n",
    "            rxns_tc = rxns_tc[0]\n",
    "\n",
    "        for name, y in speciesdct.items():\n",
    "#             plt.figure()\n",
    "            if name == \"MBP-GVSEYG\":\n",
    "                plt.plot(time, y, label = name)\n",
    "                plt.legend(loc = \"center right\")\n",
    "                plt.title(eng.path)\n",
    "\n",
    "\n",
    "\n",
    "        rxndct[k] = pd.DataFrame(speciesdct, index = time)\n",
    "        rxndct[k].loc[:, 'Path'] = eng.path\n",
    "        rxndct[k].loc[:, 'Reaction'] = k\n",
    "        dflist.append(rxndct[k])\n",
    "        # ---------------------------------------------------------------------------\n",
    "        self.datadct = rxndct\n",
    "    except Exception: \n",
    "        print(\"{} failed\".format(eng.path))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6e6873bbde1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdflist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \"\"\"\n\u001b[1;32m--> 274\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "data_df = pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_species = \"MBP-GVSEYG\"\n",
    "l = []\n",
    "n = np.array([])\n",
    "for name, df in data_df.groupby(['Path', 'Reaction']):\n",
    "    \n",
    "    df[key_species].plot(label = str(name[0][37:-7]))\n",
    "    plt.legend(loc = 'upper right', bbox_to_anchor=(1.8, 1))\n",
    "    l.append(np.array(df[key_species]))\n",
    "arr = np.array(l)\n",
    "print(arr)\n",
    "yg = arr[:, 2] - arr[:, 0]\n",
    "yg\n",
    "t = data_df.index.unique()\n",
    "xg = float(t[2]) -float(t[0])\n",
    "g = yg/xg\n",
    "\n",
    "# delete negative gradients \n",
    "arr = arr[g>0, :]\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(arr, axis = 0)\n",
    "mean = np.mean(arr, axis = 0)\n",
    "# plt.plot(t, mean)\n",
    "plt.errorbar(t, mean, std)\n",
    "plt.xlabel('Time / s')\n",
    "plt.ylabel('Normalised Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
