{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plate_map as pm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from unidec_modules import unidectools as ud\n",
    "from copy import deepcopy \n",
    "from unidec_modules.v3_SeqChrom import *\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"D:\\\\161121 CTB ratios\"]\n",
    "map_paths = [\"C:\\\\Users\\\\cm19ljc\\\\Documents\\\\GitHub\\\\UniDec\\\\reaction maps\\\\CTB ratio map.xlsx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_maps(self, groupby = 'Reaction'):\n",
    "\n",
    "    \n",
    "\n",
    "    # Reaction OR Substrate Conc\n",
    "\n",
    "    self.pmap2 = self.pmap[self.pmap['Type'] != 'empty']\n",
    "    self.pmap2.loc[:, 'Species'] = np.nan\n",
    "\n",
    "    for skey, sval in self.speciesmap.groupby(['Reaction']):\n",
    "        splist = [Species(spval.to_dict('records')[0], name = spkey) for spkey, spval in sval.groupby('Species')]\n",
    "        splist = colorcodeclass(splist)\n",
    "\n",
    "        for s in splist:\n",
    "            self.pmap2.loc[:, s.__name__] = np.nan\n",
    "            self.pmap2.loc[self.pmap2['Reaction']==skey, s.__name__] = self.pmap2.apply(lambda _:deepcopy(s), axis = 1)\n",
    "\n",
    "        spnames = [s.__name__ for s in splist]\n",
    "        self.pmap2.loc[self.pmap2['Reaction']==skey, 'Species'] = self.pmap2.apply(lambda _:spnames, axis = 1)\n",
    "\n",
    "    # update_vars\n",
    "\n",
    "    if len(self.data.spectra) == len(self.pmap2):\n",
    "        for i, s in enumerate(self.data.spectra):\n",
    "            well_id = self.pmap2.index[i]\n",
    "            timevar = self.pmap2['Time'].iloc[i]\n",
    "            s.attrs['Variable 1'] = well_id\n",
    "            s.var1 = well_id\n",
    "            s.attrs['Variable 2'] = timevar\n",
    "            s.var2 = timevar\n",
    "            self.pmap2.loc[well_id, 'Spectra'] = s\n",
    "\n",
    "\n",
    "\n",
    "    spectra = {s.var1:s for s in self.data.spectra}\n",
    "\n",
    "    # update species with well info/metadata \n",
    "\n",
    "    groupby = 'Reaction' # Reaction OR Substrate Conc\n",
    "\n",
    "    for index, row in self.pmap2.iterrows():\n",
    "        for specs in row['Species']:\n",
    "            row[specs] = deepcopy(row[specs])\n",
    "            row[specs].coord = row.name\n",
    "    #         print(row[specs])\n",
    "            vals = row[~row.index.isin(row['Species'])].to_dict()\n",
    "            row[specs].__dict__.update(vals)\n",
    "    return self\n",
    "            \n",
    "\n",
    "def peak_match(self, window = 10):\n",
    "    window = 10\n",
    "\n",
    "    intmat = np.array([])\n",
    "\n",
    "    for index, row in self.pmap2.iterrows():\n",
    "\n",
    "        rowints = np.array([])\n",
    "\n",
    "        specieslist = list(row[row.index.isin(row['Species'])])\n",
    "        theory_masses = np.array([sp.Mass for sp in specieslist])\n",
    "        data_masses = np.array([p.mass for p in row['Spectra'].pks.peaks])\n",
    "        pks = np.array([p for p in row['Spectra'].pks.peaks])\n",
    "\n",
    "        # match algorithm \n",
    "        tm, dm = np.meshgrid(theory_masses, data_masses)\n",
    "        diff = abs(tm - dm)\n",
    "        diff[diff>window] = np.nan\n",
    "        for i, d in enumerate(diff):\n",
    "            if np.isnan(d).all()==False:\n",
    "                minimum = np.nanargmin(d)\n",
    "                data_peak = data_masses[i]\n",
    "\n",
    "                specieslist[minimum].peak = pks[i]\n",
    "                specieslist[minimum].integral = pks[i].integral[0]\n",
    "                print(\"{}, {} = {}\".format(row[row.index.isin(row['Species'])][minimum].__name__, data_peak, pks[i]))\n",
    "\n",
    "                row[row.index.isin(row['Species'])][minimum].integral = pks[i].integral[0]\n",
    "                row[row.index.isin(row['Species'])][minimum].peak = pks[i]\n",
    "                np.append(rowints, pks[i].integral[0])\n",
    "                print(row[row.index.isin(row['Species'])][minimum].integral)\n",
    "\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_peaks(self):\n",
    "    for index, row in self.pmap2.iterrows():\n",
    "        ints = []\n",
    "        for s in row[row['Species']]:\n",
    "            if type(s.integral) != list:\n",
    "                ints.append(s.integral)\n",
    "\n",
    "    #     ints = np.array([s.integral for s in row[row['Species']]])\n",
    "        sum_ints = np.sum(ints)\n",
    "        for s in row[row['Species']]:\n",
    "            if type(s.integral) != list:\n",
    "                s.percentage = s.integral/sum_ints\n",
    "            else:\n",
    "                s.percentage = 0\n",
    "            print(\"{}:{}\".format(s.__name__, s.percentage))\n",
    "            \n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "\n",
      "UniDec Engine v.5.0.1\n",
      "\n",
      "UniDec Path: C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_bin\\UniDec.exe\n",
      "Reading mzML: D:\\161121 CTB ratios\\211112 CTB ratio E2_336220_RB7_01_80231.d.mzML\n",
      "[Warning] Not index found and build_index_from_scratch is False\n"
     ]
    },
    {
     "ename": "ParseError",
     "evalue": "no element found: line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3418\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-5-7f4ebf3165d0>\"\u001b[0m, line \u001b[0;32m14\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    eng.load_mzml(spectra_path)\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\v3_SeqChrom.py\"\u001b[0m, line \u001b[0;32m138\u001b[0m, in \u001b[0;35mload_mzml\u001b[0m\n    self.chromdat = ud.get_importer(path)\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\unidectools.py\"\u001b[0m, line \u001b[0;32m97\u001b[0m, in \u001b[0;35mget_importer\u001b[0m\n    d = mzMLimporter(path, gzmode=True)\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\mzMLimporter.py\"\u001b[0m, line \u001b[0;32m233\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    path = auto_gzip(path)\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\mzMLimporter.py\"\u001b[0m, line \u001b[0;32m29\u001b[0m, in \u001b[0;35mauto_gzip\u001b[0m\n    gzip_files(mzml_path, out_path)\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Documents\\GitHub\\UniDec\\unidec_modules\\mzMLimporter.py\"\u001b[0m, line \u001b[0;32m20\u001b[0m, in \u001b[0;35mgzip_files\u001b[0m\n    max_spec_no = pymzml.run.Reader(mzml_path).get_spectrum_count() + 10\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Anaconda3\\lib\\site-packages\\pymzml\\run.py\"\u001b[0m, line \u001b[0;32m128\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    self.iter = self._init_iter()\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Anaconda3\\lib\\site-packages\\pymzml\\run.py\"\u001b[0m, line \u001b[0;32m357\u001b[0m, in \u001b[0;35m_init_iter\u001b[0m\n    _, self.root = next(mzml_iter)\n",
      "  File \u001b[0;32m\"C:\\Users\\cm19ljc\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[0m, line \u001b[0;32m1233\u001b[0m, in \u001b[0;35miterator\u001b[0m\n    root = pullparser._close_and_return_root()\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\cm19ljc\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[1;36m, line \u001b[1;32m1280\u001b[1;36m, in \u001b[1;35m_close_and_return_root\u001b[1;36m\u001b[0m\n\u001b[1;33m    root = self._parser.close()\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mParseError\u001b[0m\u001b[1;31m:\u001b[0m no element found: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "data_df2_list = []\n",
    "\n",
    "for i, folder in enumerate(folders): \n",
    "    filenames = os.listdir(folder)\n",
    "    engines = []\n",
    "    for dname, dirs, files in os.walk(folder):\n",
    "\n",
    "        for fname in files:\n",
    "\n",
    "            if fname[-4:] == \"mzML\":\n",
    "                eng = SeqChrom()\n",
    "\n",
    "                spectra_path = os.path.join(dname, fname)\n",
    "                eng.load_mzml(spectra_path)\n",
    "                print(\"loaded {}\".format(spectra_path))\n",
    "                engines.append(eng)\n",
    "                \n",
    "    plt.figure()\n",
    "    df1 = pd.DataFrame()\n",
    "    dflist = []\n",
    "    for eng in engines:\n",
    "        try:\n",
    "            eng.config.chrom_peak_width = 0.05 \n",
    "            eng.get_chrom_peaks(lb = 1, ub = 5.5) \n",
    "            eng.add_chrom_peaks2() \n",
    "    #         eng.plot_tic(peak_windows = True)\n",
    "            eng.update_config(masslb = 10000, massub = 20000, minmz = 500, peakthresh = 0.1)\n",
    "            eng.process_data()\n",
    "            eng.run_unidec()\n",
    "            eng.pick_peaks()\n",
    "            eng.integrate_all()\n",
    "    #         eng.plot_all(dtype = 'massdat', combine = True, cmap = 'viridis', xlim = [41000, 43000])\n",
    "            rmap = eng.upload_map(map_paths[i])\n",
    "            species, wells = eng.upload_map(map_paths[i])\n",
    "            eng = process_maps(eng)\n",
    "            eng = peak_match(eng)\n",
    "            eng = normalise_peaks(eng)\n",
    "            self = eng\n",
    "            # get data\n",
    "\n",
    "            species = None\n",
    "            datatype = 'percentage'\n",
    "            rxndct = {}\n",
    "            groupby = 'Reaction'\n",
    "\n",
    "            # def extract_data(self):\n",
    "\n",
    "            rxns_tc = []\n",
    "            for k, v in self.pmap2.groupby(groupby):\n",
    "\n",
    "                time = v['Time']\n",
    "                speciesdct = {}\n",
    "                speciestimedct = {}\n",
    "\n",
    "                for index, row in v.iterrows():\n",
    "                    if species == None:\n",
    "                        species = row.Species\n",
    "\n",
    "                    if len(species) == 1:\n",
    "                        species = [species]\n",
    "\n",
    "                    for s in species:\n",
    "                        if s in speciesdct:\n",
    "                            speciesdct[s].append(getattr(row[s], datatype))\n",
    "                            speciestimedct[s].append(row['Time'])\n",
    "\n",
    "                        else:\n",
    "                            speciesdct[s] = [getattr(row[s], datatype)]\n",
    "                            speciestimedct[s] = [row['Time']]\n",
    "                df = pd.DataFrame(speciesdct, index = time)\n",
    "                rxns_tc.append(df)\n",
    "\n",
    "            if len(rxns_tc) == 1:\n",
    "                rxns_tc = rxns_tc[0]\n",
    "\n",
    "            for name, y in speciesdct.items():\n",
    "    #             plt.figure()\n",
    "                if name == \"CTB-H6\":\n",
    "                    plt.plot(time, y, label = name)\n",
    "                    plt.legend(loc = \"center right\")\n",
    "                    plt.title(eng.path)\n",
    "\n",
    "\n",
    "\n",
    "            rxndct[k] = pd.DataFrame(speciesdct, index = time)\n",
    "            rxndct[k].loc[:, 'Path'] = eng.path\n",
    "            rxndct[k].loc[:, 'Reaction'] = k\n",
    "            dflist.append(rxndct[k])\n",
    "            # ---------------------------------------------------------------------------\n",
    "            self.datadct = rxndct\n",
    "        except Exception: \n",
    "            print(\"{} failed\".format(eng.path))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    data_df = pd.concat(dflist)\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_species = \"CTB-H6\"\n",
    "    l = []\n",
    "    n = np.array([])\n",
    "    for name, df in data_df.groupby(['Path', 'Reaction']):\n",
    "\n",
    "        df[key_species].plot(label = str(name[0][37:-7]))\n",
    "        plt.legend(loc = 'upper right', bbox_to_anchor=(1.8, 1))\n",
    "        l.append(np.array(df[key_species]))\n",
    "    arr = np.array(l)\n",
    "\n",
    "    yg = arr[:, 2] - arr[:, 0]\n",
    "    t = data_df.index.unique()\n",
    "    xg = float(t[2]) -float(t[0])\n",
    "    g = yg/xg\n",
    "\n",
    "    # delete negative gradients \n",
    "    arr = arr[g>0, :]\n",
    "    std = np.std(arr, axis = 0)\n",
    "    mean = np.mean(arr, axis = 0)\n",
    "    plt.plot(t, mean)\n",
    "    plt.errorbar(t, mean, std)\n",
    "    plt.xlabel('Time / s')\n",
    "    plt.ylabel('Normalised Area')\n",
    "    plt.show()\n",
    "    \n",
    "    data_df.loc[:, 'Cat conc'] = folder\n",
    "    data_df2_list.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf2 = pd.concat(data_df2_list)\n",
    "datadf2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, d in datadf2.groupby(['Path']):\n",
    "    d[key_species].plot(marker = 'x')\n",
    "    plt.title(d.Path.unique())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Path', 'Reaction', 'Cat conc']\n",
    "species = list(datadf2[datadf2.columns[~datadf2.columns.isin(cols)]].columns)\n",
    "\n",
    "\n",
    "for name, d in datadf2.groupby(['Path']):\n",
    "    plt.figure()\n",
    "    for key_species in species:\n",
    "        d[key_species].plot(marker = 'x')\n",
    "        plt.title(d.Path.unique())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = datadf2.reset_index().groupby('Time').mean()\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex = True, dpi = 100)\n",
    "# for name, d in datadf2.groupby(['Path']):\n",
    "for i, key_species in enumerate(species):\n",
    "        \n",
    "\n",
    "    arr = np.array([np.array(d[key_species]) for name, d in datadf2.reset_index().groupby('Time')])\n",
    "    means = means.sort_values(by ='Time')\n",
    "    means.index = means.index.astype(float)\n",
    "    t = means.index.unique()\n",
    "    std = np.std(arr, axis = 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    ax[i].errorbar(t, means[key_species], std, label = key_species, capsize = 5, fmt = 'none')\n",
    "    ax[i].set_xlabel('Time / s')\n",
    "    ax[i].set_ylabel('Percentage Area')\n",
    "#     means[key_species].plot(legend = key_species, marker = 'x')\n",
    "    ax[i].legend(loc = 'center right')\n",
    "#     ax[i].grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([np.array(x[key_species]) for name, x in df.groupby('Time')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# des_df = datadf2.reset_index().groupby(['Cat conc', 'Time']).describe()#.reset_index()\n",
    "# for name, dfs in des_df[key_species].groupby(['Cat conc']):\n",
    "    \n",
    "#     dfs = dfs.reset_index()\n",
    "#     dfs['Time'] = dfs['Time'].astype(float)\n",
    "#     dfs = dfs.sort_values(by = 'Time').reset_index(drop = True)\n",
    "#     dfs.plot(x = 'Time', y = 'mean')\n",
    "#     plt.errorbar(dfs['Time'], dfs['mean'], dfs['std'])\n",
    "#     plt.title(name)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n, d in datadf2.reset_index().groupby(['Cat conc', 'Time']):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 5\n",
    "dflist = []\n",
    "for n, d in datadf2.reset_index().groupby(['Cat conc', 'Time']):\n",
    "    timepoints = np.array(d[key_species])\n",
    "    # discount anomolies (speak to supervisors about this/other method)\n",
    "    l = np.array([y for y in timepoints if y < (timepoints*thresh).all()])\n",
    "    \n",
    "    newdf = pd.DataFrame(l, columns = [key_species])\n",
    "#     newdf = pd.DataFrame([ser])\n",
    "\n",
    "    newdf['Cat conc'] = n[0]\n",
    "    newdf['Time'] = n[1]\n",
    "    \n",
    "    dflist.append(newdf)\n",
    "ks_df = pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_df = ks_df.reset_index().groupby(['Cat conc', 'Time']).describe()#.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, dfs in des_df[key_species].groupby(['Cat conc']):\n",
    "    \n",
    "    dfs = dfs.reset_index()\n",
    "    dfs['Time'] = dfs['Time'].astype(float)\n",
    "    dfs = dfs.sort_values(by = 'Time').reset_index(drop = True)\n",
    "#     dfs.plot(x = 'Time', y = 'mean')\n",
    "    ax.errorbar(dfs['Time'], dfs['mean'], dfs['std'], capsize = 5, fmt = 'none')\n",
    "    l = name[-2:] + \"% Catalyst\"\n",
    "    ax.scatter(dfs['Time'], dfs['mean'], label = l, marker = 'x')\n",
    "    ax.legend(bbox_to_anchor = (1.4, 1), loc = \"upper right\")\n",
    "    ax.set_xlabel('Time /s')\n",
    "    ax.set_ylabel('Percentage Species')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
